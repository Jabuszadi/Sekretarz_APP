# minimal_mcp_server.py
import config
import asyncio
import json
import logging
import os
import uuid
import mimetypes
from datetime import datetime
from fastmcp import FastMCP, Context, Client
from file_handlers import cleanup_temp_dir, job_temp_storage
from ingest import ingest_transcription
from minutes_service import generate_and_save_minutes
from pathlib import Path
from qdrant_handler import initialize_qdrant_resources, search_all_collections, get_all_collection_names, CollectionInfo
from typing import Any, Dict, List, Optional, Tuple, Type, Union, Callable
from utils import (
    extract_date_from_filename,
    get_current_ram_usage_gb,
    get_current_vram_usage_gb,
    get_diarization_models,
    get_file_creation_date,
    get_relevant_date_for_file,
    save_minutes_to_file,
    load_enrolled_speakers
)
from processor import process_audio, convert_mkv_to_wav as convert_to_wav
import shutil
import tempfile
from models import TranscriptionSegment

from summarizer import gemini_model, generate_minutes_of_meeting, generate_chat_response


from agents.database_agent import mcp_database

from fastapi import FastAPI, Request, Form, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel, Field, create_model

import httpx
from contextlib import asynccontextmanager

# === LLAMAINDEX IMPORTS ===
from llama_index.core.tools import FunctionTool
from llama_index.llms.google_genai import GoogleGenAI
from llama_index.core.agent import ReActAgent
from llama_index.core.llms import ChatMessage, MessageRole
from workflows.errors import WorkflowRuntimeError
from fastmcp.client import Client, StreamableHttpTransport
# --- ZMIENNE GLOBALNE ---
mcp_router_client = FastMCP()

# --- Modele Pydantic ---
class ChatQuery(BaseModel):
    query: str = Field(..., description="Zapytanie u≈ºytkownika do chatbota.")

class ToolCall(BaseModel):
    tool_name: str = Field(..., description="Nazwa narzƒôdzia do wywo≈Çania.")
    parameters: Dict[str, Any] = Field(..., description="Parametry do przekazania narzƒôdziu.")

class ChatResponse(BaseModel):
    response: str = Field(..., description="Odpowied≈∫ chatbota.")
    tool_calls: List[ToolCall] = Field(default_factory=list, description="Lista sugerowanych wywo≈Ça≈Ñ narzƒôdzi FastMCP.")

class ListCollectionsParams(BaseModel):
    limit: Optional[int] = Field(None, description="Opcjonalny limit liczby kolekcji do wy≈õwietlenia.")

class QueryMeetingDataParams(BaseModel):
    file_id: Optional[str] = Field(None, description="ID pliku, dla kt√≥rego szukamy danych.")
    query: str = Field(..., description="Zapytanie tekstowe do przeszukania danych spotkania.")

class GetByIdParams(BaseModel):
    id: int = Field(..., description="ID rekordu w bazie danych.")

class GetByFileIdParams(BaseModel):
    file_id: int = Field(..., description="ID pliku w tabeli processed_files.")

class ExecuteSQLQueryParams(BaseModel):
    query: str = Field(..., description="Zapytanie SQL do wykonania (tylko SELECT).")

class GetTranscriptContentParams(BaseModel):
    file_id: int = Field(..., description="ID pliku, dla kt√≥rego nale≈ºy pobraƒá tre≈õƒá transkrypcji.")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("uvicorn.access").setLevel(logging.WARNING)

class ProcessedFileSummary(BaseModel):
    id: int
    filename: str
    status: str
    processed_at: str
    filepath: Optional[str] = None
    filehash: Optional[str] = None
    api_response: Optional[str] = None
    error_message: Optional[str] = None

class TranscriptRecord(BaseModel):
    id: int
    content: str
    transcript_path: str
    created_at: str

class TranscriptSummary(BaseModel):
    id: int
    transcript_path: str
    created_at: str

class MeetingMinutesRecord(BaseModel):
    id: int
    summary_text: str
    minutes_path: str
    generated_at: str
    llm_model: Optional[str] = None
    embeddings_model: Optional[str] = None
    chunking_method: Optional[str] = None
    transcription_model: Optional[str] = None
    diarization_model: Optional[str] = None
    created_at: str

class MeetingMinutesSummary(BaseModel):
    id: int
    minutes_path: str
    summary_text: str
    generated_at: str
    created_at: str

class MeetingDataRecord(BaseModel):
    id: int
    file_id: int
    transcript_id: int
    minutes_id: int
    meeting_date: str
    qdrant_collection_name: str
    created_at: str

class GetByFilenameParams(BaseModel):
    filename: str = Field(..., description="Nazwa pliku do wyszukania.")

class AddMeetingMinutesParams(BaseModel):
    summary_text: str
    minutes_path: str
    generated_at: str
    llm_model: Optional[str] = None
    embeddings_model: Optional[str] = None
    chunking_method: Optional[str] = None
    transcription_model: Optional[str] = None
    diarization_model: Optional[str] = None
    meeting_date_str: Optional[str] = None
    existing_minutes_id: Optional[int] = None

class UpdateMeetingDataMinutesIdParams(BaseModel):
    file_id: int
    minutes_id: int

# Zmodyfikowana inicjalizacja z wykorzystaniem lifespan
@asynccontextmanager
async def lifespan(app: FastAPI):
    global router_llamaindex_agent
    logging.info("Starting up Minimal FastMCP Server (API & Router)...")
    try:
        await initialize_qdrant_resources()
        logging.info("‚úÖ Qdrant resources initialized.")
        load_enrolled_speakers()
        logging.info("‚úÖ Enrolled speaker profiles loaded.")

        db_agent_url = "http://127.0.0.1:8002/mcp/"
        logging.info(f"Attempting to connect to Database Agent at {db_agent_url}")

        # === ZMIANA: U≈ºyj tymczasowego klienta do discovery, potem utw√≥rz wrappery ===
        db_agent_tools = []
        max_retries = 10
        retry_delay = 1  # seconds
        db_agent_tools_raw = None
        
        for i in range(max_retries):
            try:
                # U≈ºyj tymczasowego klienta z kontekstem async with
                transport = StreamableHttpTransport(db_agent_url)
                async with Client(transport) as temp_client:
                    db_agent_tools_raw = await temp_client.list_tools()
                logging.info(f"‚úÖ Successfully connected to Database Agent at {db_agent_url} after {i+1} attempts.")
                break # Po≈ÇƒÖczenie udane, wyjd≈∫ z pƒôtli
            except Exception as e:
                logging.warning(f"Attempt {i+1}/{max_retries}: Error connecting to Database Agent at {db_agent_url}: {e}")
                if i < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                else:
                    logging.error(f"‚ùå Failed to connect to Database Agent after {max_retries} attempts.")
                    raise # Rethrow exception if all retries fail

        # Po≈ÇƒÖczenie udane, kontynuuj przetwarzanie narzƒôdzi
        try:
            for i, tool_info in enumerate(db_agent_tools_raw):
                logging.info(f"DEBUG: Processing remote tool {i}: Name={tool_info.name}")
                parameters_schema_dict = {}
                if hasattr(tool_info, 'parameters'):
                    if isinstance(tool_info.parameters, dict):
                        parameters_schema_dict = tool_info.parameters
                    elif hasattr(tool_info.parameters, 'model_dump'):
                        parameters_schema_dict = tool_info.parameters.model_dump()

                tool_args_model = _json_schema_to_pydantic_model(tool_info.name, parameters_schema_dict)

                # === ZMIANA: Wrapper tworzy nowe po≈ÇƒÖczenie dla ka≈ºdego wywo≈Çania ===
                def make_remote_tool_wrapper(tool_name_closure):
                    async def remote_tool_wrapper(**kwargs):
                        transport = StreamableHttpTransport(db_agent_url)
                        async with Client(transport) as client:
                            return await client.call_tool(tool_name_closure, kwargs)
                    return remote_tool_wrapper

                db_agent_tools.append(FunctionTool.from_defaults(
                    fn=make_remote_tool_wrapper(tool_info.name),
                    name=tool_info.name,
                    description=tool_info.description or f"Remote tool: {tool_info.name}",
                    fn_schema=tool_args_model
                ))
                logging.info(f"‚úÖ Successfully added remote LlamaIndex tool: {tool_info.name}")
            logging.info(f"Loaded {len(db_agent_tools)} tools from Database Agent.")
            logging.info("‚úÖ Successfully connected to Database Agent for tool discovery.")
        except Exception as e:
            logging.error(f"‚ùå Error connecting to or listing tools from Database Agent: {e}", exc_info=True)
            raise

        # === LLAMAINDEX LLM & AGENT SETUP (bez zmian) ===
        router_llm = GoogleGenAI(
            model=config.GEMINI_MODEL_NAME,
            api_key=config.GOOGLE_API_KEY,
            temperature=0.1,
        )
        logging.info(f"‚úÖ Successfully initialized Router LLM (LlamaIndex Gemini): {config.GEMINI_MODEL_NAME}")

        # Gather local router tools as FunctionTool for llamaindex (bez zmian)
        local_router_tools = []
        local_router_tools_raw = await mcp_router_client._list_tools()
        for tool_info in local_router_tools_raw:
            try:
                parameters_schema_dict = {}
                if hasattr(tool_info, 'parameters'):
                    if isinstance(tool_info.parameters, dict):
                        parameters_schema_dict = tool_info.parameters
                    elif hasattr(tool_info.parameters, 'model_dump'):
                        parameters_schema_dict = tool_info.parameters.model_dump()

                tool_args_model = _json_schema_to_pydantic_model(tool_info.name, parameters_schema_dict)

                async def tool_wrapper(*args, _tool_name=tool_info.name, **kwargs):
                    return await mcp_router_client.call_tool(_tool_name, kwargs)

                local_router_tools.append(FunctionTool.from_defaults(
                    fn=tool_wrapper,
                    name=tool_info.name,
                    description=tool_info.description or f"Local tool: {tool_info.name}",
                    fn_schema=tool_args_model
                ))
                logging.info(f"‚úÖ Successfully added local LlamaIndex tool: {tool_info.name}")
            except Exception as e:
                logging.error(f"‚ùå Error adding local tool {tool_info.name}: {e}")

        all_tools = local_router_tools + db_agent_tools
        logging.info(f"Total tools available to router LlamaIndex agent: {len(all_tools)}")


        router_llamaindex_agent = ReActAgent(
            tools=all_tools,
            llm=router_llm,
            verbose=True,
            system_prompt=(
                "Jeste≈õ inteligentnym asystentem AI. Twoim zadaniem jest odpowiadanie na pytania u≈ºytkownika, u≈ºywajƒÖc dostƒôpnych narzƒôdzi.\n"
                "**≈öCI≈öLE PRZESTRZEGAJ PONI≈ªSZYCH ZASAD WYBORU NARZƒòDZI:**\n"
                "\n"
                "1.  **DO BEZPO≈öREDNIEGO WYSZUKIWANIA TRANSKRYPT√ìW (po s≈Çowach kluczowych, temacie, fragmentach tre≈õci, m√≥wcy):**\n"
                "    -   **Zawsze u≈ºyj narzƒôdzia `search_transcripts_semantic` lub `search_transcripts_sql`.**\n"
                "    -   `search_transcripts_semantic` jest domy≈õlne dla og√≥lnych zapyta≈Ñ tematycznych (np. 'Kt√≥ry transkrypt dotyczy [temat]?', 'Znajd≈∫ fragmenty o [temat]').\n"
                "    -   `search_transcripts_sql` u≈ºyj, je≈õli u≈ºytkownik prosi o wyszukiwanie po konkretnym m√≥wcy (`speaker`) lub dok≈Çadnym tek≈õcie (`text_query`) w segmentach, ewentualnie z zakresem czasowym (`time_from`, `time_to`).\n"
                "    -   Przyk≈Çad dla `search_transcripts_semantic`: `search_transcripts_semantic(query='cross-validation')`.\n"
                "    -   Przyk≈Çad dla `search_transcripts_sql`: `search_transcripts_sql(speaker='Maciej', text_query='bud≈ºet')`.\n"
                "    -   **NIE U≈ªYWAJ `chat_with_transcripts` DO TEGO CELU!**\n"
                "\n"
                "2.  **DO ANALIZY I PODSUMOWYWANIA TRE≈öCI TRANSKRYPT√ìW (swobodna rozmowa, g≈Çƒôbsza analiza):**\n"
                "    -   U≈ºyj narzƒôdzia `chat_with_transcripts`.\n"
                "    -   To narzƒôdzie s≈Çu≈ºy do pyta≈Ñ wymagajƒÖcych zrozumienia kontekstu i generowania podsumowa≈Ñ (np. 'Podsumuj mi spotkanie', 'Co by≈Ço powiedziane o bud≈ºecie?', 'Wyja≈õnij mi X z transkryptu').\n"
                "    -   Parametr: `query` (string). Przyk≈Çad: `chat_with_transcripts(query='Podsumuj spotkanie o cross-validation')`.\n"
                "\n"
                "3.  **DO WY≈öWIETLANIA LISTY TRANSKRYPT√ìW (wszystkie, top X, bottom X):**\n"
                "    -   `get_transcripts_with_minutes()`: Dla wszystkich transkrypt√≥w z podsumowaniami (NIE przyjmuje parametr√≥w).\n"
                "    -   `get_top_transcripts(limit=X)`: Dla top X najnowszych transkrypt√≥w.\n"
                "    -   `get_bottom_transcripts(limit=X)`: Dla bottom X najstarszych transkrypt√≥w.\n"
                "\n"
                "4.  **DO WYKONANIA ZAPYTANIA SQL (gdy u≈ºytkownik prosi o surowe dane z bazy):**\n"
                "    -   U≈ºyj `execute_sql_query(query='TWOJE ZAPYTANIE SQL')` (tylko SELECT).\n"
                "\n"
                "Zawsze dostarczaj zwiƒôz≈ÇƒÖ i bezpo≈õredniƒÖ odpowied≈∫ u≈ºytkownikowi, bazujƒÖc na wynikach narzƒôdzi. Je≈õli narzƒôdzie zwr√≥ci pusty wynik, poinformuj o tym u≈ºytkownika."
            )
        )


        logging.info("‚úÖ Router LlamaIndex ReActAgent initialized with all tools.")

        logging.info("üéâ Minimal FastMCP Server startup complete!")
        yield
    finally:
        logging.info("Shutting down Minimal FastMCP Server...\n")
        # === USUNIƒòTO: Nie ma ju≈º globalnego db_agent_client do zamykania ===
        cleanup_temp_dir()
        logging.info("Minimal FastMCP Server shutdown complete.\n")

app = FastAPI(lifespan=lifespan)
templates = Jinja2Templates(directory=".")

app.mount("/mcp_api", mcp_router_client)
app.mount("/static", StaticFiles(directory="static"), name="static")

# === NARZƒòDZIA FASTMCP (hostowane przez ten serwer - Router) ===

@mcp_router_client.tool()
async def process_audio_and_summarize(
    file_path: str,
    file_job_id: str,
    output_directory: str,
    whisper_model_size: str = config.WHISPER_MODEL_SIZE,
    output_name: Optional[str] = None,
    custom_prompt: Optional[str] = None,
    chunk_duration: int = 240,
    chunk_overlap: int = 0,
    original_filename: Optional[str] = None,
) -> Dict[str, Any]:
    logging.info(f"Calling internal processing logic for {file_path}")
    return {"status": "error", "message": "process_audio_and_summarize tool not fully implemented yet."}

@mcp_router_client.tool("list_processed_files")
async def list_processed_files_tool() -> Dict[str, Any]:
    logging.info("Attempting to retrieve all processed files summary from DB via Database Agent (remote call).")
    try:
        # === ZMIANA: U≈ºyj nowego po≈ÇƒÖczenia dla ka≈ºdego wywo≈Çania ===
        transport = StreamableHttpTransport("http://127.0.0.1:8002/mcp/")
        async with Client(transport) as client:
            raw_tool_response = await client.call_tool("get_all_processed_files", {})
        return_data = await _extract_tool_output(raw_tool_response)
        return {"text_summary": return_data}
    except Exception as e:
        logging.error(f"Error listing processed files from Database Agent: {e}", exc_info=True)
        return {"error": f"WystƒÖpi≈Ç b≈ÇƒÖd podczas pobierania listy przetworzonych plik√≥w: {str(e)}"}

@mcp_router_client.tool("list_qdrant_collections", description="Wy≈õwietla listƒô dostƒôpnych kolekcji Qdrant, opcjonalnie z limitem liczby kolekcji.")
async def list_qdrant_collections_tool(params: Dict[str, Any]) -> str:
    limit = params.get("limit")
    logging.info(f"Attempting to list Qdrant collections with limit: {limit}")
    try:
        collections = await get_all_collection_names(limit=limit)
        if not collections:
            return "No Qdrant collections found."
        return "Dostƒôpne kolekcje Qdrant:\n" + "\n".join(collections)
    except Exception as e:
        logging.error(f"Error listing Qdrant collections: {e}", exc_info=True)
        return f"Error listing Qdrant collections: {e}"

@mcp_router_client.tool("search_qdrant_data", description="Wyszukuje dane w Qdrant na podstawie zapytania tekstowego. Zwraca fragmenty tre≈õci z powiƒÖzanych plik√≥w.")
async def search_qdrant_data_tool(query: str) -> List[Dict[str, Any]]:
    logging.info(f"Attempting to search Qdrant data with query: {query}")
    try:
        qdrant_results: List[Any] = await search_all_collections(query)
        if not qdrant_results:
            return [{"message": "No results found for your query."}]
        formatted_results = []
        for result in qdrant_results:
            file_id = "N/A"
            filename = "N/A"
            if hasattr(result, 'file_path') and db_agent_client:
                file_record_response = await db_agent_client.call_tool("get_file_record_by_filepath", {"filepath": result.file_path})
                if hasattr(file_record_response, 'structured_content') and file_record_response.structured_content:
                    file_record = file_record_response.structured_content
                    if file_record and not file_record.get('error'):
                        file_id = file_record.get('id', 'N/A')
                        filename = file_record.get('filename', 'N/A')
            formatted_results.append({
                "file_id": file_id,
                "filename": filename,
                "content_preview": result.content[:200] + "..." if len(result.content) > 200 else result.content,
                "full_content": result.content
            })
        return formatted_results
    except Exception as e:
        logging.error(f"Error searching Qdrant data: {e}", exc_info=True)
        return [{"error": f"Error searching Qdrant data: {e}"}]

@mcp_router_client.tool("list_directory_contents", description="Wy≈õwietla zawarto≈õƒá podanego katalogu, w tym podkatalogi i pliki. Opcjonalnie mo≈ºe byƒá rekurencyjne.")
async def list_directory_contents_tool(directory_path: str) -> Dict[str, str]:
    logging.info(f"Attempting to list contents of directory: {directory_path}")
    target_path = Path(directory_path)
    if not target_path.is_dir():
        return {"text_summary": f"B≈ÇƒÖd: Katalog '{directory_path}' nie istnieje lub nie jest katalogiem."}
    markdown_output = f"## Zawarto≈õƒá katalogu '{directory_path}':\n\n"
    def _list_directory_recursive(current_path, indent_level=0):
        nonlocal markdown_output
        indent_prefix = "    " * indent_level
        try:
            for item in sorted(os.listdir(current_path)):
                item_path = current_path / item
                if item_path.is_dir():
                    markdown_output += f"{indent_prefix}- **{item}/**\n"
                    _list_directory_recursive(item_path, indent_level + 1)
                else:
                    markdown_output += f"{indent_prefix}- {item}\n"
        except Exception as e:
            logging.error(f"Error listing directory {current_path}: {e}")
    _list_directory_recursive(target_path, 0)
    return {"text_summary": markdown_output}

@mcp_router_client.tool("generate_summary_for_processed_file", description="Generuje podsumowanie spotkania na podstawie wcze≈õniej przetworzonego pliku zidentyfikowanego po jego oryginalnej nazwie. Wykorzystuje kolekcjƒô Qdrant powiƒÖzanƒÖ z tym plikiem.")
async def generate_summary_for_processed_file_tool(filename: str, custom_prompt: Optional[str] = None) -> str:
    logging.info(f"Attempting to generate summary for file: {filename}")
    try:
        if db_agent_client is None:
            return "Database Agent client is not initialized."
        file_record_response = await db_agent_client.call_tool("get_file_record_by_filename", {"filename": filename})
        file_record = await _extract_tool_output_dict(file_record_response)
        if not file_record or file_record.get('error'):
            return f"Przepraszam, nie znaleziono pliku '{filename}' w bazie danych przetworzonych plik√≥w."
        file_id = file_record['id']
        meeting_data_record_response = await db_agent_client.call_tool("get_meeting_data_by_file_id", {"file_id": file_id})
        meeting_data_record = await _extract_tool_output_dict(meeting_data_record_response)
        if not meeting_data_record or meeting_data_record.get('error'):
            return f"Przepraszam, nie znaleziono danych spotkania dla pliku '{filename}' (ID: {file_id}). Byƒá mo≈ºe plik nie zosta≈Ç jeszcze w pe≈Çni przetworzony lub brakuje powiƒÖzanych danych."
        transcript_id = meeting_data_record.get('transcript_id')
        if not transcript_id:
            return f"Brak dostƒôpnej transkrypcji dla pliku '{filename}' (brak transcript_id w danych spotkania)."
        transcript_record_response = await db_agent_client.call_tool("get_transcript_by_id", {"id": transcript_id})
        transcript_record = await _extract_tool_output_dict(transcript_record_response)
        full_transcript_text = transcript_record.get('content') if transcript_record else None
        if not full_transcript_text:
            return f"Nie mo≈ºna pobraƒá tre≈õci transkrypcji dla ID: {transcript_id}."
        logging.info(f"Retrieved full transcript for summary generation (length: {len(full_transcript_text)}).")
        summary_response = await generate_minutes_of_meeting(full_transcript_text, custom_prompt=custom_prompt)
        if summary_response:
            logging.info(f"Summary generated for file {filename}.")
            existing_minutes_id = meeting_data_record.get('minutes_id')
            meeting_date_str = meeting_data_record.get('meeting_date')
            if not meeting_date_str:
                processed_file_response = await db_agent_client.call_tool("get_file_record_by_id", {"id": file_id})
                processed_file = await _extract_tool_output_dict(processed_file_response)
                if processed_file and not processed_file.get('error') and processed_file.get('processed_at'):
                    meeting_date_str = processed_file['processed_at'].split(' ')[0]
                else:
                    meeting_date_str = datetime.now().strftime("%Y-%m-%d")
            add_minutes_args = {
                "summary_text": json.dumps(summary_response, ensure_ascii=False),
                "minutes_path": f"{meeting_data_record.get('qdrant_collection_name', 'unknown')}_summary.txt",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "llm_model": config.GEMINI_MODEL_NAME,
                "embeddings_model": config.EMBEDDING_MODEL_NAME,
                "chunking_method": f"segmenty {config.CHUNK_DURATION}s z na≈Ço≈ºeniem {config.CHUNK_OVERLAP}s",
                "transcription_model": config.WHISPER_MODEL_SIZE,
                "diarization_model": config.PYANNOTE_PIPELINE,
                "meeting_date_str": meeting_date_str,
                "existing_minutes_id": existing_minutes_id
            }
            add_minutes_response = await db_agent_client.call_tool("add_meeting_minutes", add_minutes_args)
            minutes_id_info = await _extract_tool_output_dict(add_minutes_response)
            minutes_id = minutes_id_info.get('minutes_id') if minutes_id_info else None
            if existing_minutes_id is None and minutes_id:
                await db_agent_client.call_tool("update_meeting_data_minutes_id", {"file_id": file_id, "minutes_id": minutes_id})
            formatted_summary_parts = []
            for k, v in summary_response.items():
                formatted_summary_parts.append(f"**{k.replace('_', ' ')}:**\n{v}")
            return f"Podsumowanie dla pliku '{filename}' zosta≈Ço wygenerowane i zapisane:\n\n" + "\n\n".join(formatted_summary_parts)
        else:
            return f"Nie uda≈Ço siƒô wygenerowaƒá podsumowania dla pliku '{filename}' (odpowied≈∫ LLM by≈Ça pusta)."
    except Exception as e:
        logging.error(f"Error in MCP tool 'generate_summary_for_processed_file' for file '{filename}': {e}", exc_info=True)
        return f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd podczas generowania podsumowania dla pliku '{filename}': {e}"

@mcp_router_client.tool("get_transcript_content_for_file", description="Pobiera pe≈ÇnƒÖ tre≈õƒá transkrypcji dla danego ID pliku.")
async def get_transcript_content_for_file_tool(file_id: int) -> str:
    logging.info(f"Attempting to retrieve transcript content for file_id: {file_id}")
    try:
        if db_agent_client is None:
            return "Database Agent client is not initialized."
        meeting_data_record_response = await db_agent_client.call_tool("get_meeting_data_by_file_id", {"file_id": file_id})
        meeting_data_record = await _extract_tool_output_dict(meeting_data_record_response)
        if not meeting_data_record or meeting_data_record.get('error'):
            return f"Przepraszam, nie znaleziono danych spotkania dla pliku o ID: {file_id}. Byƒá mo≈ºe plik nie zosta≈Ç jeszcze w pe≈Çni przetworzony lub brakuje powiƒÖzanych danych."
        transcript_id = meeting_data_record.get('transcript_id')
        if not transcript_id:
            return f"Brak dostƒôpnej transkrypcji dla pliku o ID: {file_id} (brak transcript_id w danych spotkania)."
        transcript_record_response = await db_agent_client.call_tool("get_transcript_by_id", {"id": transcript_id})
        transcript_record = await _extract_tool_output_dict(transcript_record_response)
        full_transcript_text = transcript_record.get('content') if transcript_record else None
        if not full_transcript_text:
            return f"Tre≈õƒá transkrypcji dla ID: {transcript_id} jest pusta."
        return f"Pe≈Çna tre≈õƒá transkrypcji dla pliku o ID {file_id}:\n\n{full_transcript_text}"
    except Exception as e:
        logging.error(f"Error retrieving transcript content for file_id {file_id}: {e}", exc_info=True)
        return f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd podczas pobierania tre≈õci transkrypcji dla pliku o ID {file_id}: {e}"

@mcp_router_client.tool("list_transcripts", description="Wy≈õwietla wszystkie transkrypty z podsumowaniami spotka≈Ñ. U≈ºywa get_transcripts_with_minutes z Database Agent.")
async def list_transcripts_tool() -> Dict[str, Any]:
    logging.info("Attempting to retrieve transcripts with minutes from Database Agent.")
    try:
        transport = StreamableHttpTransport("http://127.0.0.1:8002/mcp/")
        async with Client(transport) as client:
            raw_tool_response = await client.call_tool("get_transcripts_with_minutes", {})
        return_data = await _extract_tool_output(raw_tool_response)
        return {"text_summary": return_data}
    except Exception as e:
        logging.error(f"Error listing transcripts from Database Agent: {e}", exc_info=True)
        return {"error": f"WystƒÖpi≈Ç b≈ÇƒÖd podczas pobierania transkrypt√≥w: {str(e)}"}

async def _extract_tool_output(tool_result: Any) -> str:
    if hasattr(tool_result, 'structured_content') and tool_result.structured_content is not None:
        if isinstance(tool_result.structured_content, list) and all(isinstance(item, str) for item in tool_result.structured_content):
            if tool_result.structured_content:
                return "\n".join(tool_result.structured_content)
            else:
                return "Brak zawarto≈õci."
        return await _extract_tool_output(tool_result.structured_content)
    elif hasattr(tool_result, 'data') and tool_result.data is not None:
        return await _extract_tool_output(tool_result.data)
    elif hasattr(tool_result, 'content') and tool_result.content:
        return "\n".join([c.text for c in tool_result.content if hasattr(c, 'text')])
    elif hasattr(tool_result, 'is_error') and tool_result.is_error:
        return f"Error from tool: {tool_result.content[0].text if hasattr(tool_result, 'content') and tool_result.content else 'Unknown error'}"
    if isinstance(tool_result, dict):
        if 'text_summary' in tool_result and isinstance(tool_result['text_summary'], str):
            return tool_result['text_summary']
        if 'error' in tool_result and isinstance(tool_result['error'], str):
            return tool_result['error']
        if 'response' in tool_result:
            return tool_result['response']
        if 'result' in tool_result and isinstance(tool_result['result'], (list, dict)):
            return await _extract_tool_output(tool_result['result'])
        if 'structuredContent' in tool_result and 'result' in tool_result['structuredContent']:
            result_content = tool_result['structuredContent']['result']
            if isinstance(result_content, list):
                if all(isinstance(item, dict) and 'file_id' in item and 'filename' in item for item in result_content):
                    markdown_output = "### Wyniki wyszukiwania w Qdrant:\n\n"
                    for item in result_content:
                        markdown_output += f"- **ID pliku:** `{item.get('file_id', 'N/A')}`\n"
                        markdown_output += f"  **Nazwa pliku:** `{item.get('filename', 'N/A')}`\n"
                        markdown_output += f"  **Fragment tre≈õci:** \"{item.get('content_preview', 'Brak podglƒÖdu.')}\"\n\n"
                    return markdown_output
                elif all(isinstance(item, dict) for item in result_content):
                    if result_content and len(set(frozenset(d.keys()) for d in result_content)) == 1:
                        headers = list(result_content[0].keys())
                        markdown_table = "| " + " | ".join(headers) + " |\n"
                        markdown_table += "|---" * len(headers) + "|\n"
                        for row in result_content:
                            values = [str(row.get(h, '')) for h in headers]
                            markdown_table += "| " + " | ".join(values) + " |\n"
                        return markdown_table
                    else:
                        return json.dumps(result_content, indent=2)
                else:
                    if result_content:
                        list_items_markdown = [f"{item}" for item in result_content]
                        return "\n".join(list_items_markdown)
                    else:
                        return "Brak zawarto≈õci."
            elif isinstance(result_content, dict):
                return json.dumps(result_content, indent=2)
            else:
                return str(result_content)
        else:
            return json.dumps(tool_result, indent=2)
    elif isinstance(tool_result, list):
        if all(isinstance(item, dict) and 'file_id' in item and 'filename' in item for item in tool_result):
            markdown_output = "### Wyniki wyszukiwania w Qdrant:\n\n"
            for item in tool_result:
                markdown_output += f"- **ID pliku:** `{item.get('file_id', 'N/A')}`\n"
                markdown_output += f"  **Nazwa pliku:** `{item.get('filename', 'N/A')}`\n"
                markdown_output += f"  **Fragment tre≈õci:** \"{item.get('content_preview', 'Brak podglƒÖdu.')}\"\n\n"
            return markdown_output
        elif all(isinstance(item, dict) for item in tool_result):
            if tool_result and len(set(frozenset(d.keys()) for d in tool_result)) == 1:
                headers = list(tool_result[0].keys())
                markdown_table = "| " + " | ".join(headers) + " |\n"
                markdown_table += "|---" * len(headers) + "|\n"
                for row in tool_result:
                    values = [str(row.get(h, '')) for h in headers]
                    markdown_table += "| " + " | ".join(values) + " |\n"
                return markdown_table
            else:
                return json.dumps(tool_result, indent=2)
        else:
            if tool_result:
                list_items_markdown = [f"{item}" for item in tool_result]
                return "\n".join(list_items_markdown)
            else:
                return "Brak zawarto≈õci."
    else:
        return str(tool_result)

async def _extract_tool_output_dict(raw_tool_response: Any) -> Optional[Dict[str, Any]]:
    if hasattr(raw_tool_response, 'structured_content') and raw_tool_response.structured_content:
        return raw_tool_response.structured_content.get('result')
    return None

def _json_schema_to_pydantic_model(tool_name: str, parameters_schema: Dict[str, Any]) -> Type[BaseModel]:
    if not parameters_schema:
        # Zwracamy dynamicznie utworzonƒÖ, pustƒÖ podklasƒô BaseModel
        return create_model(f"{tool_name.replace('-', '_').replace('.', '_').replace('/', '_')}ArgsEmpty", __base__=BaseModel)
    properties = parameters_schema.get('properties', {})
    required_fields = set(parameters_schema.get('required', []))
    fields_for_pydantic_model = {}
    for prop_name, prop_schema in properties.items():
        py_type: Type = Any
        if prop_schema.get('type') == 'string':
            py_type = str
        elif prop_schema.get('type') == 'number':
            py_type = float
        elif prop_schema.get('type') == 'integer':
            py_type = int
        elif prop_schema.get('type') == 'boolean':
            py_type = bool
        elif prop_schema.get('type') == 'array':
            items_schema = prop_schema.get('items', {})
            item_type: Type = Any
            if items_schema.get('type') == 'string': item_type = str
            elif items_schema.get('type') == 'number': item_type = float
            elif items_schema.get('type') == 'integer': item_type = int
            py_type = List[item_type]
        elif prop_schema.get('type') == 'object':
            py_type = Dict[str, Any]
        elif '$ref' in prop_schema:
            logging.warning(f"Unhandled $ref in schema for {tool_name}.{prop_name}. Defaulting to Any.")
            py_type = Any
        if prop_name in required_fields:
            fields_for_pydantic_model[prop_name] = (py_type, Field(..., description=prop_schema.get('description', '')))
        else:
            fields_for_pydantic_model[prop_name] = (Optional[py_type], Field(None, description=prop_schema.get('description', '')))
    DynamicArgsModel = create_model(
        f"{tool_name.replace('-', '_').replace('.', '_').replace('/', '_')}Args",
        **fields_for_pydantic_model,
        __base__=BaseModel
    )
    return DynamicArgsModel

# === ENDPOINTY FASTAPI ===
@app.get("/", response_class=HTMLResponse)
async def root():
    return FileResponse("chat_interface.html")

@app.get("/chat_ui", response_class=HTMLResponse)
async def serve_chat_interface(request: Request):
    return templates.TemplateResponse(request, "chat_interface.html")

@app.post("/chat/query", response_model=ChatResponse)
async def chat_query_endpoint(chat_query: ChatQuery):
    global router_llamaindex_agent
    logging.info(f"Received chat query: '{chat_query.query}' at /chat/query endpoint.")
    if router_llamaindex_agent is None:
        raise HTTPException(status_code=503, detail="Agent Router not initialized. Please try again later.")
    try:
        agent_response = await router_llamaindex_agent.run(user_msg=chat_query.query)
        logging.info(f"DEBUG: agent_response.response dir: {dir(agent_response.response)}")
        logging.info(f"DEBUG: Output from LlamaIndex agent: {agent_response.response.content}")
        return ChatResponse(response=agent_response.response.content)
    except WorkflowRuntimeError as e:
        logging.error(f"Error in chat_query_endpoint: {e}", exc_info=True)
        # Wychwyƒá bardziej szczeg√≥≈Çowe informacje o b≈Çƒôdzie, je≈õli sƒÖ dostƒôpne z WorkflowRuntimeError
        error_message = f"Przepraszam, wystƒÖpi≈Ç b≈ÇƒÖd podczas przetwarzania Twojego zapytania: {e}"
        if isinstance(e, WorkflowRuntimeError) and "list index out of range" in str(e):
            error_message = "Przepraszam, agent AI napotka≈Ç problem podczas generowania odpowiedzi (brak tre≈õci). Mo≈ºe to byƒá spowodowane filtrami bezpiecze≈Ñstwa, problemami z modelem lub niejasnym zapytaniem. Spr√≥buj zadaƒá pytanie ponownie lub przeformu≈Çowaƒá je."
        elif isinstance(e, WorkflowRuntimeError):
            error_message = f"Przepraszam, agent AI napotka≈Ç wewnƒôtrzny b≈ÇƒÖd: {e}"
        
        return ChatResponse(response=error_message)

async def _list_processed_files_logic_for_template() -> List[Dict[str, Any]]:
    processed_files: List[Dict[str, Any]] = []
    try:
        raw_files = await _list_processed_files_logic()
        if raw_files and isinstance(raw_files, str):
            import markdown
            html_content = markdown.markdown(raw_files)
            processed_files = []
        elif raw_files and isinstance(raw_files, dict) and isinstance(raw_files.get('files'), list):
            for file_data in raw_files['files']:
                if isinstance(file_data, dict):
                    processed_files.append({
                        "filename": file_data.get("filename", "N/A"),
                        "summary_path": file_data.get("minutes_filename", "N/A"),
                        "transcription_path": file_data.get("transcription_filename", "N/A")
                    })
    except Exception as e:
        logging.error(f"Error fetching processed files for HTML: {e}")
        processed_files = []
    return processed_files

@app.post("/upload-audio")
async def upload_audio(
    audio_file: UploadFile = File(...),
    user_query: Optional[str] = Form(None)
):
    job_id = str(uuid.uuid4())
    temp_dir = Path(config.UPLOAD_DIR) / job_id
    os.makedirs(temp_dir, exist_ok=True)
    file_location = temp_dir / audio_file.filename
    original_filename = audio_file.filename

    logging.info(f"Received file upload: {original_filename} (job_id: {job_id})")

    try:
        with open(file_location, "wb") as buffer:
            shutil.copyfileobj(audio_file.file, buffer)
        logging.info(f"File saved to: {file_location}")

        processed_audio_path = file_location
        mime_type, _ = mimetypes.guess_type(file_location)
        if mime_type and mime_type.startswith('video/'):
            logging.info(f"Detected video file: {original_filename}. Converting to WAV...")
            wav_filename = f"{file_location.stem}.wav"
            converted_wav_path = temp_dir / wav_filename
            if not convert_to_wav(str(file_location), str(converted_wav_path)):
                raise Exception("Video to audio conversion failed.")
            processed_audio_path = converted_wav_path
            logging.info(f"Video converted to audio: {processed_audio_path}")
        elif mime_type and not mime_type.startswith('audio/'):
            raise HTTPException(status_code=400, detail=f"Nieobs≈Çugiwany typ pliku: {mime_type}. Proszƒô przes≈Çaƒá plik audio lub wideo.")

        logging.info(f"Calling process_audio_and_summarize tool for job {job_id} on Audio Agent...")
        final_audio_processing_result = None
        tool_args = {
            "file_path": str(processed_audio_path),
            "file_job_id": job_id,
            "output_directory": str(config.OUTPUT_DIR_API_TRANSCRIPTS),
            "original_filename": original_filename,
            "custom_prompt": user_query
        }
        final_audio_processing_result = await process_audio(
            input_file=processed_audio_path,
            job_id=job_id,
            whisper_model_size=config.WHISPER_MODEL_SIZE
        )
        if final_audio_processing_result[0]:
            transcription_segments = final_audio_processing_result[0]
            transcription_filename = final_audio_processing_result[1]
            transcript_id = final_audio_processing_result[2]
            collection_name_for_file = await ingest_transcription(
                transcription_segments,
                processed_audio_path,
                job_id,
                transcript_id,
                config.CHUNK_DURATION,
                config.CHUNK_OVERLAP
            )
            minutes_content_response, minutes_filename, minutes_db_id = await generate_and_save_minutes(
                collection_name=collection_name_for_file,
                original_source_path=processed_audio_path,
                custom_prompt=user_query,
                output_name=original_filename
            )
            file_hash = await run_in_threadpool(agent_db.compute_file_hash, processed_audio_path)
            file_id = await run_in_threadpool(agent_db.add_file, original_filename, str(processed_audio_path), file_hash, "processing", "")
            await run_in_threadpool(agent_db.add_meeting_data, file_id, transcript_id, minutes_db_id, get_relevant_date_for_file(processed_audio_path), collection_name_for_file)
            await run_in_threadpool(agent_db.update_file_status, file_hash, "completed", "Processing successful")
            return JSONResponse(content={
                "status": "success",
                "message": "Audio file processed and summarized successfully.",
                "result": {
                    "transcription_filename": transcription_filename,
                    "minutes_filename": minutes_filename,
                    "collection_name": collection_name_for_file,
                    "minutes_content": minutes_content_response.model_dump() if minutes_content_response else None
                }
            })
        else:
            raise HTTPException(status_code=500, detail="Audio processing failed or produced no segments.")
    except Exception as e:
        logging.error(f"Failed to upload or start processing file for job {job_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"WystƒÖpi≈Ç b≈ÇƒÖd podczas przesy≈Çania lub przetwarzania pliku: {e}")

@app.post("/mcp_tool")
async def mcp_tool(request: Request):
    """
    Uniwersalny endpoint do wywo≈Çywania dowolnego narzƒôdzia FastMCP na agencie bazodanowym.
    Przyk≈Çad body:
    {
      "tool_name": "chat_with_transcripts",
      "params": {
        "query": "O czym by≈Ça rozmowa?",
        "collection_name": "spotkanie1"
      }
    }
    """
    data = await request.json()
    tool_name = data.get("tool_name")
    params = data.get("params", {})

    transport = StreamableHttpTransport("http://127.0.0.1:8002/mcp/")
    async with Client(transport) as client:
        result = await client.call_tool(tool_name, {"params": params})
        # Je≈õli odpowied≈∫ ma .dict(), zwr√≥ƒá jako JSON, w innym wypadku zwr√≥ƒá surowo
        if hasattr(result, "dict"):
            return JSONResponse(result.dict())
        return JSONResponse(result)

if __name__ == "__main__":
    import uvicorn
    logging.info("Starting FastAPI server with Uvicorn (Minimal MCP Server)...")
    uvicorn.run("minimal_mcp_server:app", host="0.0.0.0", port=8000, reload=True)